{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6204b0ac-ce9a-4ec9-83bd-a3a1c4c3463f",
   "metadata": {},
   "source": [
    "# Analysis Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c35f45-2d7e-41c9-815b-21b86bc9ed6c",
   "metadata": {},
   "source": [
    "## NuScenes Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c444c98-3c84-4b74-a69f-ba7f30f063d2",
   "metadata": {},
   "source": [
    "### Load reqd packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a9abc8b-3c6f-4a99-b27f-ef24af546956",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np \n",
    "import copy\n",
    "import tempfile\n",
    "import warnings\n",
    "from os import path as osp\n",
    "\n",
    "import mmcv\n",
    "import numpy as np\n",
    "import pyquaternion\n",
    "import torch\n",
    "from nuscenes.utils.data_classes import Box as NuScenesBox\n",
    "import mmcv\n",
    "from collections import defaultdict\n",
    "\n",
    "# from mmdet3d.core import bbox3d2result, box3d_multiclass_nms, xywhr2xyxyr\n",
    "# from mmdet.datasets import CocoDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c81698-09bb-4707-bc56-d4e0faf59a86",
   "metadata": {},
   "source": [
    "### Paths to val and training annotation files for image based 3D object detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7e6cf87c-879d-461e-b357-def339a1b78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_anno_file = '/home/anishmad/msr_thesis/mmdet3d-lt3d/data/nuscenes/nuscenes_infos_val_mono3d.coco.json'\n",
    "train_anno_file = '/home/anishmad/msr_thesis/mmdet3d-lt3d/data/nuscenes/nuscenes_infos_train_mono3d.coco.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7de0bb0-0ba4-464b-bc8d-201aa2b12fd5",
   "metadata": {},
   "source": [
    "### Choosing only classes present in the val set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e7af1fae-d988-4c36-92d5-1f1dcc91fe97",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\n",
    "'car', 'truck', 'trailer', 'bus', 'construction_vehicle', 'bicycle', 'motorcycle', 'emergency_vehicle',\n",
    "'adult', 'child', 'police_officer', 'construction_worker', 'stroller', 'personal_mobility', \n",
    "'pushable_pullable', 'debris', 'traffic_cone', 'barrier'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b9ea42e4-d392-4358-900b-292ece7d5a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = json.load(open(train_anno_file,'r'))\n",
    "data_val = json.load(open(val_anno_file,'r'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba47963-ec93-4bca-b805-aca62b877ecd",
   "metadata": {},
   "source": [
    "From the paper: \n",
    "\n",
    "*Formally, for the regression branch, the detector predicts\n",
    "3D attributes, including offsets ∆x, ∆y to the projected 3D center, depths d, 3D size w3D, l3D, h3D,\n",
    "sin value of rotation θ, direction class Cθ, center-ness c, and distances to four sides of 2D boxes l,\n",
    "r, t, b, for each location on the output dense map.*\n",
    "\n",
    "**bbox_cam3d in annotations represents [∆x, ∆y to the projected 3D center, depths d, 3D size w3D, l3D, h3D]**  \n",
    "This is why we multiply with classwise depth priors to first 2 indices of predictions. (see function `decode()` in `fcos3d_bbox_coder.py`)   \n",
    "\n",
    "> **Warning**  \n",
    "Note: In the original mmdet3d config the order for base_dims is given as (l3D, w3D, h3D), therefore we also follow same order to generate base_dims for classes not mentioned in the original mmdet config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bcf0905a-c131-4dda-a29b-b1e523912bdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 0, 'name': 'car'},\n",
       " {'id': 1, 'name': 'truck'},\n",
       " {'id': 2, 'name': 'trailer'},\n",
       " {'id': 3, 'name': 'bus'},\n",
       " {'id': 4, 'name': 'construction_vehicle'},\n",
       " {'id': 5, 'name': 'bicycle'},\n",
       " {'id': 6, 'name': 'motorcycle'},\n",
       " {'id': 7, 'name': 'emergency_vehicle'},\n",
       " {'id': 8, 'name': 'adult'},\n",
       " {'id': 9, 'name': 'child'},\n",
       " {'id': 10, 'name': 'police_officer'},\n",
       " {'id': 11, 'name': 'construction_worker'},\n",
       " {'id': 12, 'name': 'stroller'},\n",
       " {'id': 13, 'name': 'personal_mobility'},\n",
       " {'id': 14, 'name': 'pushable_pullable'},\n",
       " {'id': 15, 'name': 'debris'},\n",
       " {'id': 16, 'name': 'traffic_cone'},\n",
       " {'id': 17, 'name': 'barrier'}]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_val['categories']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "748dec5d-9233-47ca-88bc-7d8f37d1e071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_name': 'samples/CAM_BACK/n015-2018-07-18-11-07-57+0800__CAM_BACK__1531883533537525.jpg',\n",
       " 'image_id': '5ffc994537664bb9aefa37ee09068c79',\n",
       " 'area': 1142.9049071452464,\n",
       " 'category_name': 'car',\n",
       " 'category_id': 0,\n",
       " 'bbox': [723.0468713984644,\n",
       "  489.1449417500972,\n",
       "  37.854072475335215,\n",
       "  30.19238967986695],\n",
       " 'iscrowd': 0,\n",
       " 'bbox_cam3d': [-4.6043109342135065,\n",
       "  1.1319897855125702,\n",
       "  42.28373715976227,\n",
       "  4.25,\n",
       "  1.44,\n",
       "  1.638,\n",
       "  -1.7497131449765695],\n",
       " 'velo_cam3d': [-1.3292092789466072, 8.538864273706539],\n",
       " 'center2d': [741.1028442382812, 503.4422912597656, 42.28373718261719],\n",
       " 'attribute_name': 'vehicle.moving',\n",
       " 'attribute_id': 5,\n",
       " 'segmentation': [],\n",
       " 'id': 101}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train['annotations'][101]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2fd5c5-8d99-4e22-bde2-39ba7ed1fdd6",
   "metadata": {},
   "source": [
    "### Compute mean depth priors (classwise) for a data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83717bdc-124b-457a-9fda-2fcf93fc6aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "\n",
      "[(37.152, 24.632), (31.99, 21.124), (20.606, 13.679), (23.893, 15.209), (20.571, 14.341), (34.157, 20.107), (27.457, 15.528), (22.736, 15.011), (22.193, 16.328), (24.278, 16.049), (22.348, 13.704), (40.911, 26.341), (39.687, 23.974), (22.298, 10.944), (24.985, 12.478), (29.132, 16.155), (18.995, 12.011), (29.624, 21.013)]\n",
      "Val\n",
      "\n",
      "[(27.356, 16.619), (18.817, 12.008), (33.185, 21.504), (22.562, 13.306), (38.762, 25.564), (38.81, 25.374), (20.296, 14.837), (25.255, 14.126), (28.419, 18.421), (39.775, 21.664), (24.895, 17.914), (21.214, 13.083), (21.788, 4.532), (41.683, 21.851), (27.188, 15.182), (20.188, 10.077), (32.358, 25.091), (17.598, 16.05)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_mean_depths(data):\n",
    "    classwise_depths = defaultdict(list)\n",
    "    mean_std_depths = []\n",
    "    for idx,anno in enumerate(data['annotations']):\n",
    "        classwise_depths[anno['category_name']].append(anno['center2d'][2])\n",
    "        # l.append(anno['category_name'])\n",
    "\n",
    "    for cat, cat_depths in classwise_depths.items():\n",
    "        # print(cat, np.mean(cat_depths), np.std(cat_depths))\n",
    "        mean, std = np.round(np.mean(cat_depths),3), np.round(np.std(cat_depths),3)\n",
    "        mean_std_depths.append((mean,std))\n",
    "    print(mean_std_depths)\n",
    "    return mean_std_depths\n",
    "\n",
    "print('Train\\n')\n",
    "ms_depth_train = get_mean_depths(data_train)\n",
    "print('Val\\n')\n",
    "ms_depth_val = get_mean_depths(data_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6aec7a5-2f72-4725-ae6a-03f8df8cbb40",
   "metadata": {},
   "source": [
    "### Computing base dims for bbox sizes (length, width, height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62f4f79c-94d4-4125-a533-960d1d92ec33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "\n",
      "{'truck': (6.93, 2.83, 2.51), 'car': (4.62, 1.73, 1.96), 'traffic_cone': (0.41, 1.08, 0.41), 'construction_worker': (0.71, 1.73, 0.72), 'pushable_pullable': (0.66, 1.06, 0.6), 'construction_vehicle': (6.68, 3.21, 2.85), 'adult': (0.73, 1.77, 0.67), 'barrier': (0.5, 0.99, 2.52), 'debris': (0.9, 1.19, 0.97), 'motorcycle': (2.11, 1.46, 0.78), 'bicycle': (1.7, 1.29, 0.61), 'bus': (11.22, 3.5, 2.95), 'trailer': (12.56, 3.89, 2.94), 'child': (0.53, 1.38, 0.51), 'stroller': (0.94, 1.19, 0.62), 'police_officer': (0.69, 1.82, 0.73), 'personal_mobility': (1.18, 1.74, 0.62), 'emergency_vehicle': (5.06, 1.88, 2.04)}\n",
      "Val\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_mean_basedims(data):\n",
    "    classwise_dims = defaultdict(lambda: defaultdict(list))\n",
    "    for idx,anno in enumerate(data['annotations']):\n",
    "        classwise_dims[anno['category_name']]['length'].append(anno['bbox_cam3d'][3])  # corresponding to w3D?\n",
    "        classwise_dims[anno['category_name']]['width'].append(anno['bbox_cam3d'][4])  # corresponding to l3D?\n",
    "        classwise_dims[anno['category_name']]['height'].append(anno['bbox_cam3d'][5])   # corresponding to h3D?\n",
    "        \n",
    "        # l.append(anno['category_name'])\n",
    "    \n",
    "    mean_dims_dict = {}\n",
    "    for cat, cat_dims_dict in classwise_dims.items():\n",
    "        mean_length, mean_length_std = np.round(np.mean(cat_dims_dict['length']),2), np.round(np.std(cat_dims_dict['length']),2)\n",
    "        mean_width, mean_width_std = np.round(np.mean(cat_dims_dict['width']),2), np.round(np.std(cat_dims_dict['width']),2)\n",
    "        mean_height, mean_height_std = np.round(np.mean(cat_dims_dict['height']),2), np.round(np.std(cat_dims_dict['height']),2)        \n",
    "        # print(cat, np.mean(cat_depths), np.std(cat_depths))\n",
    "        # print(cat, mean_length, mean_length_std, mean_width, mean_width_std, mean_height, mean_height_std)\n",
    "        mean_dims_dict[cat] = (mean_length, mean_width , mean_height)\n",
    "    return mean_dims_dict\n",
    "\n",
    "print('Train\\n')\n",
    "tr_mean_dims = get_mean_basedims(data_train)\n",
    "print(tr_mean_dims)\n",
    "ordered_tr_mean_dim_vals = [tr_mean_dims[x] for x in class_names]\n",
    "print('Val\\n')\n",
    "val_mean_dims = get_mean_basedims(data_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ec1176-2baf-4152-90ae-c7c014f3ab6f",
   "metadata": {},
   "source": [
    "### Compute Base Dims for NuScenes dataset (used in PGD config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c85be37f-9dbe-4ba7-8a8e-1efb935f900c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======\n",
      "Loading NuScenes tables for version v1.0-trainval...\n",
      "23 category,\n",
      "8 attribute,\n",
      "4 visibility,\n",
      "64386 instance,\n",
      "12 sensor,\n",
      "10200 calibrated_sensor,\n",
      "2631083 ego_pose,\n",
      "68 log,\n",
      "850 scene,\n",
      "34149 sample,\n",
      "2631083 sample_data,\n",
      "1166187 sample_annotation,\n",
      "4 map,\n",
      "Done loading in 38.391 seconds.\n",
      "======\n",
      "Reverse indexing ...\n",
      "Done reverse indexing in 8.2 seconds.\n",
      "======\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from nuscenes.nuscenes import NuScenes\n",
    "\n",
    "nusc = NuScenes(version=\"v1.0-trainval\", dataroot='/ssd0/nperi/nuScenes/', verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821bbde0-3d10-4fcf-a76e-9912d8b074ac",
   "metadata": {},
   "source": [
    "### List Categories in the dataset along with statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "701071f0-d3c2-4f97-93dd-5ed1a6382512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category stats for split v1.0-trainval:\n",
      "animal                      n=  787, width= 0.37±0.13, len= 0.86±0.36, height= 0.60±0.20, lw_aspect= 2.35±0.69\n",
      "human.pedestrian.adult      n=208240, width= 0.67±0.13, len= 0.73±0.19, height= 1.77±0.18, lw_aspect= 1.11±0.26\n",
      "human.pedestrian.child      n= 2066, width= 0.51±0.14, len= 0.53±0.15, height= 1.38±0.25, lw_aspect= 1.05±0.23\n",
      "human.pedestrian.constructi n= 9161, width= 0.72±0.20, len= 0.71±0.20, height= 1.74±0.30, lw_aspect= 1.02±0.29\n",
      "human.pedestrian.personal_m n=  395, width= 0.62±0.12, len= 1.18±0.31, height= 1.71±0.27, lw_aspect= 1.98±0.64\n",
      "human.pedestrian.police_off n=  727, width= 0.73±0.14, len= 0.69±0.13, height= 1.83±0.14, lw_aspect= 0.97±0.18\n",
      "human.pedestrian.stroller   n= 1072, width= 0.63±0.13, len= 0.95±0.27, height= 1.17±0.15, lw_aspect= 1.58±0.68\n",
      "human.pedestrian.wheelchair n=  503, width= 0.77±0.10, len= 1.09±0.23, height= 1.37±0.09, lw_aspect= 1.42±0.23\n",
      "movable_object.barrier      n=152087, width= 2.53±0.64, len= 0.50±0.17, height= 0.98±0.15, lw_aspect= 0.21±0.14\n",
      "movable_object.debris       n= 3016, width= 1.01±0.67, len= 1.08±1.17, height= 1.26±0.46, lw_aspect= 1.09±0.72\n",
      "movable_object.pushable_pul n=24605, width= 0.60±0.27, len= 0.67±0.44, height= 1.06±0.27, lw_aspect= 1.11±0.30\n",
      "movable_object.trafficcone  n=97959, width= 0.41±0.13, len= 0.41±0.14, height= 1.07±0.27, lw_aspect= 1.03±0.24\n",
      "static_object.bicycle_rack  n= 2713, width= 6.79±5.55, len= 4.69±4.81, height= 1.32±0.26, lw_aspect= 2.03±2.74\n",
      "vehicle.bicycle             n=11859, width= 0.60±0.16, len= 1.70±0.26, height= 1.28±0.34, lw_aspect= 3.03±0.83\n",
      "vehicle.bus.bendy           n= 1820, width= 2.96±0.23, len= 9.83±1.70, height= 3.45±0.21, lw_aspect= 3.33±0.59\n",
      "vehicle.bus.rigid           n=14501, width= 2.93±0.33, len=11.23±2.07, height= 3.47±0.52, lw_aspect= 3.84±0.63\n",
      "vehicle.car                 n=493322, width= 1.95±0.19, len= 4.62±0.46, height= 1.73±0.24, lw_aspect= 2.37±0.20\n",
      "vehicle.construction        n=14671, width= 2.85±1.06, len= 6.37±3.13, height= 3.19±1.02, lw_aspect= 2.27±0.89\n",
      "vehicle.emergency.ambulance n=   49, width= 2.18±0.10, len= 5.40±0.24, height= 2.45±0.04, lw_aspect= 2.49±0.21\n",
      "vehicle.emergency.police    n=  638, width= 2.03±0.14, len= 5.04±0.33, height= 1.85±0.19, lw_aspect= 2.49±0.15\n",
      "vehicle.motorcycle          n=12617, width= 0.77±0.17, len= 2.11±0.32, height= 1.47±0.23, lw_aspect= 2.81±0.55\n",
      "vehicle.trailer             n=24860, width= 2.90±0.53, len=12.29±4.52, height= 3.87±0.75, lw_aspect= 4.17±1.39\n",
      "vehicle.truck               n=88519, width= 2.51±0.45, len= 6.93±2.17, height= 2.84±0.84, lw_aspect= 2.75±0.56\n"
     ]
    }
   ],
   "source": [
    "nusc.list_categories()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c84811a-4a53-4df3-aa88-f9fc3b98c114",
   "metadata": {},
   "source": [
    "### Manually copied over values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f5f5578-f0a0-4511-bd06-4415dcd8ce4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### All classes listed as given in config https://github.com/neeharperi/mmdet3d-lt3d/blob/main/configs/_base_/datasets/nus-mono3d.py \n",
    "# class_names = [\n",
    "# 'car', 'truck', 'trailer', 'bus', 'construction_vehicle', 'bicycle', 'motorcycle', 'emergency_vehicle',\n",
    "# 'adult', 'child', 'police_officer', 'construction_worker', 'stroller', 'personal_mobility', \n",
    "# 'pushable_pullable', 'debris', 'traffic_cone', 'barrier'\n",
    "# ]\n",
    "\n",
    "## follow (len, height, width) convention.  There are slight differences in values probably due to using trainval set and not simply train set.\n",
    "## If slighlty different values are an issue, use method for base_depths to compute base_dims over the train set.\n",
    "\n",
    "base_dims = { 'car': (4.62, 1.73, 1.96), 'truck': (6.93, 2.83, 2.51), 'trailer': (12.56, 3.89, 2.94), 'bus': (11.22, 3.50, 2.95),\n",
    "            'construction_vehicle': (6.68, 3.21, 2.85), 'bicycle': (1.70, 1.28, 0.60), 'motorcycle': (2.11, 1.46, 0.78),\n",
    "             'emergency_vehicle': (5.04, 1.85, 2.03), 'adult': (0.73, 1.77, 0.67), 'child': (0.53, 1.38, 0.51), \n",
    "             'police_officer': (0.69, 1.83, 0.73), 'construction_worker': (0.71, 1.74, 0.72), 'stroller': (0.95, 1.17, 0.63), \n",
    "             'personal_mobility': (1.18, 1.71, 0.62), 'pushable_pullable': (0.67, 1.06, 0.60), 'debris': (1.08, 1.26, 1.01), \n",
    "             'traffic_cone': (0.41, 1.07, 0.41), 'barrier':(0.5, 0.98, 2.53)\n",
    "            }\n",
    "\n",
    "# classes not included\n",
    "## animal,  wheelchair, bicycle_rack, bendy_bus, (only taken emergency vehicle as police vehicle, not ambulance), "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452be033-05d0-4f49-aaed-34f2dd85daae",
   "metadata": {},
   "source": [
    "#### Check difference between values already computed for trainval set, and specifically when computed for train set (no val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c869e917-9429-4771-8899-2402d5c19061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((4.62, 1.73, 1.96), (4.62, 1.73, 1.96)),\n",
       " ((6.93, 2.83, 2.51), (6.93, 2.83, 2.51)),\n",
       " ((12.56, 3.89, 2.94), (12.56, 3.89, 2.94)),\n",
       " ((11.22, 3.5, 2.95), (11.22, 3.5, 2.95)),\n",
       " ((6.68, 3.21, 2.85), (6.68, 3.21, 2.85)),\n",
       " ((1.7, 1.28, 0.6), (1.7, 1.29, 0.61)),\n",
       " ((2.11, 1.46, 0.78), (2.11, 1.46, 0.78)),\n",
       " ((5.04, 1.85, 2.03), (5.06, 1.88, 2.04)),\n",
       " ((0.73, 1.77, 0.67), (0.73, 1.77, 0.67)),\n",
       " ((0.53, 1.38, 0.51), (0.53, 1.38, 0.51)),\n",
       " ((0.69, 1.83, 0.73), (0.69, 1.82, 0.73)),\n",
       " ((0.71, 1.74, 0.72), (0.71, 1.73, 0.72)),\n",
       " ((0.95, 1.17, 0.63), (0.94, 1.19, 0.62)),\n",
       " ((1.18, 1.71, 0.62), (1.18, 1.74, 0.62)),\n",
       " ((0.67, 1.06, 0.6), (0.66, 1.06, 0.6)),\n",
       " ((1.08, 1.26, 1.01), (0.9, 1.19, 0.97)),\n",
       " ((0.41, 1.07, 0.41), (0.41, 1.08, 0.41)),\n",
       " ((0.5, 0.98, 2.53), (0.5, 0.99, 2.52))]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(list(base_dims.values()), ordered_tr_mean_dim_vals))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b723593-b66d-45ff-8296-093ba745fd83",
   "metadata": {},
   "source": [
    "#### THe correct one to use is the one computed using only the trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "de39a2cb-85f7-47fd-8f7c-410b4307fbb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4.62, 1.73, 1.96),\n",
       " (6.93, 2.83, 2.51),\n",
       " (12.56, 3.89, 2.94),\n",
       " (11.22, 3.5, 2.95),\n",
       " (6.68, 3.21, 2.85),\n",
       " (1.7, 1.29, 0.61),\n",
       " (2.11, 1.46, 0.78),\n",
       " (5.06, 1.88, 2.04),\n",
       " (0.73, 1.77, 0.67),\n",
       " (0.53, 1.38, 0.51),\n",
       " (0.69, 1.82, 0.73),\n",
       " (0.71, 1.73, 0.72),\n",
       " (0.94, 1.19, 0.62),\n",
       " (1.18, 1.74, 0.62),\n",
       " (0.66, 1.06, 0.6),\n",
       " (0.9, 1.19, 0.97),\n",
       " (0.41, 1.08, 0.41),\n",
       " (0.5, 0.99, 2.52)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordered_tr_mean_dim_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143307f0-b2e5-49fd-a569-28f60fec1e3e",
   "metadata": {},
   "source": [
    "### Create COCO Structure using Symlinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "faf065de-920b-49d9-976e-3742777d2fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_anno_path = '/home/anishmad/msr_thesis/glip/DATASET/nuscenes/annotations/'\n",
    "os.makedirs(new_anno_path, exist_ok=True)\n",
    "new_imgs_path = '/home/anishmad/msr_thesis/glip/DATASET/nuscenes/images/'\n",
    "os.makedirs(new_imgs_path, exist_ok=True)\n",
    "# os.symlink('/ssd0/nperi/nuScenes/samples', '/home/anishmad/msr_thesis/glip/DATASET/nuscenes/images/samples', target_is_directory=True)\n",
    "# os.symlink('/home/anishmad/msr_thesis/mmdet3d-lt3d/data/nuscenes/nuscenes_infos_val_mono3d.coco.json','/home/anishmad/msr_thesis/glip/DATASET/nuscenes/annotations/nuscenes_infos_val_mono3d.coco.json')\n",
    "os.symlink('/home/anishmad/msr_thesis/mmdet3d-lt3d/data/nuscenes/nuscenes_infos_train_mono3d.coco.json','/home/anishmad/msr_thesis/glip/DATASET/nuscenes/annotations/nuscenes_infos_train_mono3d.coco.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cad3cc46-c5e3-4dd4-b3e8-e0087da9d3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = torch.load('/home/anishmad/msr_thesis/glip/results/coco/zero-shot-coco-eval/eval/glip_tiny_model_o365_goldg_cc_sbu/inference/coco_2017_val/predictions.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2265095f-02fb-46ba-9b6a-136e340ffdc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_copy_extra_fields',\n",
       " '_jit_unwrap',\n",
       " '_jit_wrap',\n",
       " '_split_into_xyxy',\n",
       " 'add_field',\n",
       " 'area',\n",
       " 'bbox',\n",
       " 'clip_to_image',\n",
       " 'concate_box_list',\n",
       " 'convert',\n",
       " 'copy_with_fields',\n",
       " 'crop',\n",
       " 'extra_fields',\n",
       " 'fields',\n",
       " 'get_field',\n",
       " 'has_field',\n",
       " 'mode',\n",
       " 'resize',\n",
       " 'size',\n",
       " 'to',\n",
       " 'transpose']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(preds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4bc369ce-6014-4a88-9418-24345c92f22d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 409.4594,   11.5031,  486.7885,   73.2527],\n",
       "        [ 543.0848,   64.0387,  612.6340,  116.1780],\n",
       "        [ 948.3429,  157.3511, 1001.9305,  252.7081],\n",
       "        [ 841.1035,  225.6266,  864.5202,  265.3079],\n",
       "        [ 894.3657,  256.1796,  984.2666,  326.8865],\n",
       "        [ 931.5273,  265.4379,  984.4628,  326.2958],\n",
       "        [ 893.7115,  256.3721,  983.4470,  326.7967],\n",
       "        [ 893.7115,  256.3721,  983.4470,  326.7967],\n",
       "        [ 922.8558,  287.8022,  941.9806,  322.8975],\n",
       "        [ 932.4453,  288.8634,  942.5273,  323.3798],\n",
       "        [ 437.8874,  260.3157,  497.8688,  398.8068],\n",
       "        [ 722.8879,  323.7018,  750.4893,  387.0290],\n",
       "        [ 437.6594,  328.6328,  497.5798,  397.9185],\n",
       "        [ 438.0580,  328.3372,  497.5044,  398.3215],\n",
       "        [ 624.9235,  331.3458,  710.9141,  416.6017],\n",
       "        [ 589.0894,  359.7681,  606.6123,  401.2081],\n",
       "        [ 589.0894,  359.7681,  606.6123,  401.2081],\n",
       "        [ 589.0894,  359.7681,  606.6123,  401.2081],\n",
       "        [ 625.5745,  352.8468,  648.2319,  402.8647],\n",
       "        [ 804.6076,  353.0910,  829.0630,  412.1364],\n",
       "        [ 968.1994,  366.9663,  988.5522,  387.4816],\n",
       "        [ 454.4431,  370.7512,  474.8858,  398.1999],\n",
       "        [ 627.7640,  361.6844,  650.9243,  403.2560],\n",
       "        [ 625.5687,  332.6192,  710.4187,  430.2346],\n",
       "        [ 744.6305,  375.6030,  764.2552,  405.0989],\n",
       "        [ 636.0693,  379.1391,  649.4449,  403.0996],\n",
       "        [ 649.7325,  364.2413,  683.4227,  436.0244],\n",
       "        [ 649.7325,  364.2413,  683.4227,  436.0244],\n",
       "        [ 744.7780,  375.9517,  764.2075,  405.6140],\n",
       "        [ 744.7780,  375.9517,  764.2075,  405.6140],\n",
       "        [ 744.7780,  375.9517,  764.2075,  405.6140],\n",
       "        [ 962.0543,  386.5881,  987.7188,  415.2663],\n",
       "        [ 962.0543,  386.5881,  987.7188,  415.2663],\n",
       "        [ 962.0543,  386.5881,  987.7188,  415.2663],\n",
       "        [ 570.8184,  399.9836,  674.0026,  428.5609],\n",
       "        [ 658.6899,  388.8788,  677.5447,  433.1846],\n",
       "        [ 658.6899,  388.8788,  677.5447,  433.1846],\n",
       "        [ 594.4161,  410.0610,  637.0212,  432.7859],\n",
       "        [ 677.8657,  402.2739,  700.6569,  434.0773],\n",
       "        [ 677.8657,  402.2739,  700.6569,  434.0773],\n",
       "        [ 677.8657,  402.2739,  700.6569,  434.0773],\n",
       "        [ 677.8657,  402.2739,  700.6569,  434.0773],\n",
       "        [ 658.9401,  409.1961,  677.3260,  433.9148],\n",
       "        [ 658.9401,  409.1961,  677.3260,  433.9148],\n",
       "        [ 610.8088,  432.6300,  685.5338,  438.2498],\n",
       "        [ 921.2289,  327.2582,  961.2905,  535.5688],\n",
       "        [ 313.5762,  438.0120,  348.6531,  501.3803],\n",
       "        [ 313.5762,  438.0120,  348.6531,  501.3803],\n",
       "        [ 313.5762,  438.0120,  348.6531,  501.3803],\n",
       "        [ 313.5762,  438.0120,  348.6531,  501.3803],\n",
       "        [ 594.3406,  410.9267,  650.7699,  537.0513],\n",
       "        [ 960.8878,  419.9338, 1013.6151,  520.1872],\n",
       "        [ 745.3615,  417.1725,  789.4683,  546.9944],\n",
       "        [ 767.7592,  414.3953,  827.6360,  568.9535],\n",
       "        [ 922.7083,  447.3652,  960.1997,  531.3237],\n",
       "        [ 263.1786,  520.4769,  369.4934,  547.1835],\n",
       "        [1041.7048,  546.1954, 1080.8052,  621.0560],\n",
       "        [ 395.5705,  562.8794,  481.3275,  614.9750],\n",
       "        [ 395.5705,  562.8794,  481.3275,  614.9750],\n",
       "        [ 395.5705,  562.8794,  481.3275,  614.9750],\n",
       "        [ 395.5705,  562.8794,  481.3275,  614.9750],\n",
       "        [1041.7338,  546.3647, 1080.8815,  621.5670],\n",
       "        [1136.3257,  539.2209, 1198.9915,  666.8436],\n",
       "        [1136.3676,  540.1069, 1198.8749,  667.6649],\n",
       "        [1136.3676,  540.1069, 1198.8749,  667.6649],\n",
       "        [1136.3676,  540.1069, 1198.8749,  667.6649],\n",
       "        [ 170.1202,  613.6914,  205.4336,  626.2057],\n",
       "        [ 409.2007,    3.2046,  611.6369,  117.1221],\n",
       "        [ 771.2696,  296.0970,  871.0165,  555.1705],\n",
       "        [ 836.3996,  316.7412,  962.3813,  536.9073],\n",
       "        [ 917.1635,  325.7962,  961.5814,  531.9200],\n",
       "        [ 802.8293,  305.4567,  915.4669,  552.6172],\n",
       "        [ 802.8293,  305.4567,  915.4669,  552.6172],\n",
       "        [ 566.0775,  408.4588,  660.5359,  561.8762],\n",
       "        [ 575.8207,  409.7005,  661.0612,  556.4549],\n",
       "        [ 646.4692,  400.6121,  712.8372,  558.7980],\n",
       "        [ 840.9011,  417.3226,  922.7365,  530.7576],\n",
       "        [1048.1790,  389.2454, 1198.8179,  542.5731],\n",
       "        [1048.1790,  389.2454, 1198.8179,  542.5731],\n",
       "        [ 571.6315,  407.1107,  699.9827,  575.2272],\n",
       "        [ 607.6982,  424.7903,  737.8216,  584.0811],\n",
       "        [ 730.6259,  412.6129,  828.1669,  582.9524],\n",
       "        [ 547.1181,  409.5517,  657.3923,  596.2289],\n",
       "        [ 557.0624,  410.2456,  661.9449,  589.2576],\n",
       "        [ 615.6674,  419.6891,  794.0974,  596.8195],\n",
       "        [ 679.7308,  412.6977,  778.0815,  596.3354],\n",
       "        [ 679.7308,  412.6977,  778.0815,  596.3354],\n",
       "        [ 558.1902,  425.2779,  721.4284,  599.5626],\n",
       "        [ 598.9604,  431.1396,  727.3096,  597.7377],\n",
       "        [1030.8274,  468.5518, 1129.9902,  754.4015],\n",
       "        [1036.4395,  531.7830, 1198.6826,  664.5583],\n",
       "        [1031.2009,  467.9403, 1128.9141,  751.4004],\n",
       "        [1032.6229,  565.8840, 1099.4594,  752.3961],\n",
       "        [1032.6229,  565.8840, 1099.4594,  752.3961],\n",
       "        [  12.2433,  311.3900,  288.8667,  501.9533],\n",
       "        [ 766.1049,  298.6443,  872.2720,  553.2258],\n",
       "        [ 594.8378,  421.3986,  834.5995,  596.4493],\n",
       "        [ 549.4150,  423.5292,  760.5236,  599.3220],\n",
       "        [ 234.0807,  674.1806,  883.1782,  797.1279],\n",
       "        [ 911.0211,  659.8108, 1199.4866,  797.2687]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0].bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c81d021-e5f0-4ee0-9e49-c08b0beaaf25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bf8502-d160-44cc-8cb7-a0370c65c534",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad9d392-9f7c-4127-b558-70c7033106ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b18ff2-f8aa-4367-9fce-090d13112f47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3186143-1377-4d7c-a229-e1568bf61973",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b07df6df-5742-45c6-8de9-9dadf5442d87",
   "metadata": {},
   "source": [
    "## Argoverse 2 Dataset (use trinity 2-9 for accessing this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f8bfa8b3-4e3b-4ebe-803e-72a50f67ab5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "av2_data_path = '/ssd0/nperi/Sensor/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c30001c2-d152-4bed-a909-23953711cc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "av2_val_anno_file = '/ssd0/nperi/Sensor/av2_mmdet3d_trainval/av2_infos_val_mono3d.coco.json'\n",
    "av2_train_anno_file = '/ssd0/nperi/Sensor/av2_mmdet3d_trainval/av2_infos_train_mono3d.coco.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "04d67657-21f7-4791-a0bd-e4a3598a5cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "av2_class_names = [\n",
    "    'REGULAR_VEHICLE', 'PEDESTRIAN', 'BICYCLIST', 'MOTORCYCLIST', 'WHEELED_RIDER',\n",
    "    'BOLLARD', 'CONSTRUCTION_CONE', 'SIGN', 'CONSTRUCTION_BARREL', 'STOP_SIGN', 'MOBILE_PEDESTRIAN_CROSSING_SIGN',\n",
    "    'LARGE_VEHICLE', 'BUS', 'BOX_TRUCK', 'TRUCK', 'VEHICULAR_TRAILER', 'TRUCK_CAB', 'SCHOOL_BUS', 'ARTICULATED_BUS',\n",
    "    'MESSAGE_BOARD_TRAILER', 'BICYCLE', 'MOTORCYCLE', 'WHEELED_DEVICE', 'WHEELCHAIR', 'STROLLER', 'DOG'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d24f028-8768-4121-81fb-4f3e981c5723",
   "metadata": {},
   "outputs": [],
   "source": [
    "av2_data_train = json.load(open(av2_train_anno_file,'r'))\n",
    "av2_data_val = json.load(open(av2_val_anno_file,'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e6e60157-909f-4786-933b-6cfba22e1fd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['annotations', 'images', 'categories'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "av2_data_val.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4fdfa314-d2c0-4705-921d-aa3f18e172d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_av2_mean_depths(data):\n",
    "    classwise_depths = defaultdict(list)\n",
    "    mean_std_depths = []\n",
    "    for idx,annotations in enumerate(data['annotations']):\n",
    "        for anno in annotations:\n",
    "            classwise_depths[anno['category_name']].append(anno['center2d'][2])\n",
    "        # l.append(anno['category_name'])\n",
    "\n",
    "    for cat, cat_depths in classwise_depths.items():\n",
    "        # print(cat, np.mean(cat_depths), np.std(cat_depths))\n",
    "        mean, std = np.round(np.mean(cat_depths),3), np.round(np.std(cat_depths),3)\n",
    "        mean_std_depths.append((mean,std))\n",
    "    print(mean_std_depths)\n",
    "    return mean_std_depths\n",
    "\n",
    "# print('Train\\n')\n",
    "# ms_depth_train = get_mean_depths(data_train)\n",
    "# print('Val\\n')\n",
    "# ms_depth_val = get_mean_depths(data_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d16c63ae-200a-4b8b-9a54-209c71e41aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "\n",
      "[(67.916, 49.937), (46.656, 33.858), (56.606, 40.822), (38.339, 28.203), (76.658, 50.601), (54.712, 40.125), (73.337, 48.471), (37.717, 30.003), (55.527, 41.531), (37.9, 28.919), (63.728, 45.957), (56.305, 41.804), (56.094, 42.341), (70.247, 51.26), (35.152, 24.898), (44.353, 30.747), (42.142, 32.147), (48.5, 36.594), (39.861, 28.927), (29.193, 19.689), (61.041, 46.659), (62.564, 47.949), (50.827, 39.056), (43.389, 31.502), (71.797, 52.945), (97.331, 50.898)]\n",
      "Val\n",
      "\n",
      "[(47.375, 34.212), (57.413, 41.079), (56.439, 40.694), (41.256, 31.124), (61.638, 38.635), (40.423, 28.701), (69.278, 48.788), (43.791, 30.888), (56.478, 41.139), (84.919, 53.948), (40.12, 30.18), (61.358, 46.853), (58.87, 50.133), (56.71, 49.369), (37.246, 22.41), (72.569, 51.317), (32.471, 24.265), (39.031, 26.855), (42.536, 28.846), (60.113, 42.958), (75.775, 54.038), (40.235, 30.475), (52.551, 37.513), (62.898, 4.456), (58.963, 39.803), (61.372, 36.554)]\n"
     ]
    }
   ],
   "source": [
    "print('Train\\n')\n",
    "av2_mean_depth_train = get_av2_mean_depths(av2_data_train)\n",
    "print('Val\\n')\n",
    "av2_mean_depth_val = get_av2_mean_depths(av2_data_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ce70da94-40a3-47be-b90f-f13be51f806f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AV2 Train\n",
      "\n",
      "{'BUS': (11.67, 2.97, 3.3), 'PEDESTRIAN': (0.7, 0.77, 1.76), 'REGULAR_VEHICLE': (4.48, 1.94, 1.73), 'WHEELCHAIR': (0.98, 0.76, 1.15), 'LARGE_VEHICLE': (6.66, 2.68, 3.05), 'SIGN': (0.44, 1.51, 2.6), 'BOX_TRUCK': (7.7, 2.81, 3.5), 'CONSTRUCTION_CONE': (0.36, 0.33, 0.88), 'CONSTRUCTION_BARREL': (0.69, 0.66, 1.09), 'STROLLER': (0.87, 0.65, 1.2), 'TRUCK': (9.79, 2.85, 3.35), 'VEHICULAR_TRAILER': (7.42, 2.87, 3.26), 'STOP_SIGN': (0.36, 0.98, 3.09), 'TRUCK_CAB': (7.64, 3.32, 3.65), 'WHEELED_DEVICE': (1.26, 0.6, 1.38), 'BOLLARD': (0.36, 0.31, 1.06), 'MOTORCYCLE': (1.86, 0.73, 1.34), 'MOTORCYCLIST': (1.26, 0.85, 1.63), 'BICYCLE': (1.65, 0.62, 1.23), 'DOG': (1.0, 0.45, 0.8), 'ARTICULATED_BUS': (10.54, 2.94, 3.29), 'SCHOOL_BUS': (8.93, 2.79, 3.1), 'BICYCLIST': (1.12, 0.81, 1.77), 'WHEELED_RIDER': (0.82, 0.73, 1.81), 'MOBILE_PEDESTRIAN_CROSSING_SIGN': (0.32, 0.99, 1.42), 'MESSAGE_BOARD_TRAILER': (3.25, 3.2, 3.75)}\n"
     ]
    }
   ],
   "source": [
    "def get_av2_mean_basedims(data):\n",
    "    classwise_dims = defaultdict(lambda: defaultdict(list))\n",
    "    for idx,annotations in enumerate(data['annotations']):\n",
    "        for anno in annotations:\n",
    "            classwise_dims[anno['category_name']]['length'].append(anno['bbox_cam3d'][3])  # corresponding to w3D?\n",
    "            classwise_dims[anno['category_name']]['width'].append(anno['bbox_cam3d'][4])  # corresponding to l3D?\n",
    "            classwise_dims[anno['category_name']]['height'].append(anno['bbox_cam3d'][5])   # corresponding to h3D?\n",
    "\n",
    "        # l.append(anno['category_name'])\n",
    "    \n",
    "    mean_dims_dict = {}\n",
    "    for cat, cat_dims_dict in classwise_dims.items():\n",
    "        mean_length, mean_length_std = np.round(np.mean(cat_dims_dict['length']),2), np.round(np.std(cat_dims_dict['length']),2)\n",
    "        mean_width, mean_width_std = np.round(np.mean(cat_dims_dict['width']),2), np.round(np.std(cat_dims_dict['width']),2)\n",
    "        mean_height, mean_height_std = np.round(np.mean(cat_dims_dict['height']),2), np.round(np.std(cat_dims_dict['height']),2)        \n",
    "        # print(cat, np.mean(cat_depths), np.std(cat_depths))\n",
    "        # print(cat, mean_length, mean_length_std, mean_width, mean_width_std, mean_height, mean_height_std)\n",
    "        mean_dims_dict[cat] = (mean_length, mean_width , mean_height)\n",
    "    return mean_dims_dict\n",
    "\n",
    "print('AV2 Train\\n')\n",
    "av2_tr_mean_dims = get_av2_mean_basedims(av2_data_train)\n",
    "print(av2_tr_mean_dims)\n",
    "ordered_av2_tr_mean_dim_vals = [av2_tr_mean_dims[x] for x in av2_class_names]\n",
    "# print('Val\\n')\n",
    "# av2_val_mean_dims = get_av2_mean_basedims(av2_data_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3566c156-e622-4535-b03c-3cb2713ed4b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4.48, 1.94, 1.73),\n",
       " (0.7, 0.77, 1.76),\n",
       " (1.12, 0.81, 1.77),\n",
       " (1.26, 0.85, 1.63),\n",
       " (0.82, 0.73, 1.81),\n",
       " (0.36, 0.31, 1.06),\n",
       " (0.36, 0.33, 0.88),\n",
       " (0.44, 1.51, 2.6),\n",
       " (0.69, 0.66, 1.09),\n",
       " (0.36, 0.98, 3.09),\n",
       " (0.32, 0.99, 1.42),\n",
       " (6.66, 2.68, 3.05),\n",
       " (11.67, 2.97, 3.3),\n",
       " (7.7, 2.81, 3.5),\n",
       " (9.79, 2.85, 3.35),\n",
       " (7.42, 2.87, 3.26),\n",
       " (7.64, 3.32, 3.65),\n",
       " (8.93, 2.79, 3.1),\n",
       " (10.54, 2.94, 3.29),\n",
       " (3.25, 3.2, 3.75),\n",
       " (1.65, 0.62, 1.23),\n",
       " (1.86, 0.73, 1.34),\n",
       " (1.26, 0.6, 1.38),\n",
       " (0.98, 0.76, 1.15),\n",
       " (0.87, 0.65, 1.2),\n",
       " (1.0, 0.45, 0.8)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordered_av2_tr_mean_dim_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "22550d90-236b-4631-adaa-55939740d429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 0, 'name': 'REGULAR_VEHICLE'},\n",
       " {'id': 1, 'name': 'PEDESTRIAN'},\n",
       " {'id': 2, 'name': 'BICYCLIST'},\n",
       " {'id': 3, 'name': 'MOTORCYCLIST'},\n",
       " {'id': 4, 'name': 'WHEELED_RIDER'},\n",
       " {'id': 5, 'name': 'BOLLARD'},\n",
       " {'id': 6, 'name': 'CONSTRUCTION_CONE'},\n",
       " {'id': 7, 'name': 'SIGN'},\n",
       " {'id': 8, 'name': 'CONSTRUCTION_BARREL'},\n",
       " {'id': 9, 'name': 'STOP_SIGN'},\n",
       " {'id': 10, 'name': 'MOBILE_PEDESTRIAN_CROSSING_SIGN'},\n",
       " {'id': 11, 'name': 'LARGE_VEHICLE'},\n",
       " {'id': 12, 'name': 'BUS'},\n",
       " {'id': 13, 'name': 'BOX_TRUCK'},\n",
       " {'id': 14, 'name': 'TRUCK'},\n",
       " {'id': 15, 'name': 'VEHICULAR_TRAILER'},\n",
       " {'id': 16, 'name': 'TRUCK_CAB'},\n",
       " {'id': 17, 'name': 'SCHOOL_BUS'},\n",
       " {'id': 18, 'name': 'ARTICULATED_BUS'},\n",
       " {'id': 19, 'name': 'MESSAGE_BOARD_TRAILER'},\n",
       " {'id': 20, 'name': 'BICYCLE'},\n",
       " {'id': 21, 'name': 'MOTORCYCLE'},\n",
       " {'id': 22, 'name': 'WHEELED_DEVICE'},\n",
       " {'id': 23, 'name': 'WHEELCHAIR'},\n",
       " {'id': 24, 'name': 'STROLLER'},\n",
       " {'id': 25, 'name': 'DOG'}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "av2_data_val['categories']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e37fa59d-732c-4833-ae96-9078e2e8e1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# av2_data_val['annotations'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "df40ff03-2fcc-4994-9835-9de314d7b621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# av2_data_val['images'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91326e9-d0fe-4ba2-8e92-a6b4ca3083bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11dc51a1-28ae-4873-a467-39a894908c36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7fa91711-3e6b-4d7f-b292-8130f055acf5",
   "metadata": {},
   "source": [
    "## COCO Dataset Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a7f5f87b-59d1-4aa7-99f1-f53f42a88acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_coco_anno_file = '/home/anishmad/msr_thesis/glip/coco_data/annotations/instances_val2017.json'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e9645993-3d9a-4a4d-9b79-61177afa9d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_val_coco = json.load(open(val_coco_anno_file,'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d84c5fc9-c89b-4ccf-bb66-196636da41a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'supercategory': 'person', 'id': 1, 'name': 'person'},\n",
       " {'supercategory': 'vehicle', 'id': 2, 'name': 'bicycle'},\n",
       " {'supercategory': 'vehicle', 'id': 3, 'name': 'car'},\n",
       " {'supercategory': 'vehicle', 'id': 4, 'name': 'motorcycle'},\n",
       " {'supercategory': 'vehicle', 'id': 5, 'name': 'airplane'},\n",
       " {'supercategory': 'vehicle', 'id': 6, 'name': 'bus'},\n",
       " {'supercategory': 'vehicle', 'id': 7, 'name': 'train'},\n",
       " {'supercategory': 'vehicle', 'id': 8, 'name': 'truck'},\n",
       " {'supercategory': 'vehicle', 'id': 9, 'name': 'boat'},\n",
       " {'supercategory': 'outdoor', 'id': 10, 'name': 'traffic light'},\n",
       " {'supercategory': 'outdoor', 'id': 11, 'name': 'fire hydrant'},\n",
       " {'supercategory': 'outdoor', 'id': 13, 'name': 'stop sign'},\n",
       " {'supercategory': 'outdoor', 'id': 14, 'name': 'parking meter'},\n",
       " {'supercategory': 'outdoor', 'id': 15, 'name': 'bench'},\n",
       " {'supercategory': 'animal', 'id': 16, 'name': 'bird'},\n",
       " {'supercategory': 'animal', 'id': 17, 'name': 'cat'},\n",
       " {'supercategory': 'animal', 'id': 18, 'name': 'dog'},\n",
       " {'supercategory': 'animal', 'id': 19, 'name': 'horse'},\n",
       " {'supercategory': 'animal', 'id': 20, 'name': 'sheep'},\n",
       " {'supercategory': 'animal', 'id': 21, 'name': 'cow'},\n",
       " {'supercategory': 'animal', 'id': 22, 'name': 'elephant'},\n",
       " {'supercategory': 'animal', 'id': 23, 'name': 'bear'},\n",
       " {'supercategory': 'animal', 'id': 24, 'name': 'zebra'},\n",
       " {'supercategory': 'animal', 'id': 25, 'name': 'giraffe'},\n",
       " {'supercategory': 'accessory', 'id': 27, 'name': 'backpack'},\n",
       " {'supercategory': 'accessory', 'id': 28, 'name': 'umbrella'},\n",
       " {'supercategory': 'accessory', 'id': 31, 'name': 'handbag'},\n",
       " {'supercategory': 'accessory', 'id': 32, 'name': 'tie'},\n",
       " {'supercategory': 'accessory', 'id': 33, 'name': 'suitcase'},\n",
       " {'supercategory': 'sports', 'id': 34, 'name': 'frisbee'},\n",
       " {'supercategory': 'sports', 'id': 35, 'name': 'skis'},\n",
       " {'supercategory': 'sports', 'id': 36, 'name': 'snowboard'},\n",
       " {'supercategory': 'sports', 'id': 37, 'name': 'sports ball'},\n",
       " {'supercategory': 'sports', 'id': 38, 'name': 'kite'},\n",
       " {'supercategory': 'sports', 'id': 39, 'name': 'baseball bat'},\n",
       " {'supercategory': 'sports', 'id': 40, 'name': 'baseball glove'},\n",
       " {'supercategory': 'sports', 'id': 41, 'name': 'skateboard'},\n",
       " {'supercategory': 'sports', 'id': 42, 'name': 'surfboard'},\n",
       " {'supercategory': 'sports', 'id': 43, 'name': 'tennis racket'},\n",
       " {'supercategory': 'kitchen', 'id': 44, 'name': 'bottle'},\n",
       " {'supercategory': 'kitchen', 'id': 46, 'name': 'wine glass'},\n",
       " {'supercategory': 'kitchen', 'id': 47, 'name': 'cup'},\n",
       " {'supercategory': 'kitchen', 'id': 48, 'name': 'fork'},\n",
       " {'supercategory': 'kitchen', 'id': 49, 'name': 'knife'},\n",
       " {'supercategory': 'kitchen', 'id': 50, 'name': 'spoon'},\n",
       " {'supercategory': 'kitchen', 'id': 51, 'name': 'bowl'},\n",
       " {'supercategory': 'food', 'id': 52, 'name': 'banana'},\n",
       " {'supercategory': 'food', 'id': 53, 'name': 'apple'},\n",
       " {'supercategory': 'food', 'id': 54, 'name': 'sandwich'},\n",
       " {'supercategory': 'food', 'id': 55, 'name': 'orange'},\n",
       " {'supercategory': 'food', 'id': 56, 'name': 'broccoli'},\n",
       " {'supercategory': 'food', 'id': 57, 'name': 'carrot'},\n",
       " {'supercategory': 'food', 'id': 58, 'name': 'hot dog'},\n",
       " {'supercategory': 'food', 'id': 59, 'name': 'pizza'},\n",
       " {'supercategory': 'food', 'id': 60, 'name': 'donut'},\n",
       " {'supercategory': 'food', 'id': 61, 'name': 'cake'},\n",
       " {'supercategory': 'furniture', 'id': 62, 'name': 'chair'},\n",
       " {'supercategory': 'furniture', 'id': 63, 'name': 'couch'},\n",
       " {'supercategory': 'furniture', 'id': 64, 'name': 'potted plant'},\n",
       " {'supercategory': 'furniture', 'id': 65, 'name': 'bed'},\n",
       " {'supercategory': 'furniture', 'id': 67, 'name': 'dining table'},\n",
       " {'supercategory': 'furniture', 'id': 70, 'name': 'toilet'},\n",
       " {'supercategory': 'electronic', 'id': 72, 'name': 'tv'},\n",
       " {'supercategory': 'electronic', 'id': 73, 'name': 'laptop'},\n",
       " {'supercategory': 'electronic', 'id': 74, 'name': 'mouse'},\n",
       " {'supercategory': 'electronic', 'id': 75, 'name': 'remote'},\n",
       " {'supercategory': 'electronic', 'id': 76, 'name': 'keyboard'},\n",
       " {'supercategory': 'electronic', 'id': 77, 'name': 'cell phone'},\n",
       " {'supercategory': 'appliance', 'id': 78, 'name': 'microwave'},\n",
       " {'supercategory': 'appliance', 'id': 79, 'name': 'oven'},\n",
       " {'supercategory': 'appliance', 'id': 80, 'name': 'toaster'},\n",
       " {'supercategory': 'appliance', 'id': 81, 'name': 'sink'},\n",
       " {'supercategory': 'appliance', 'id': 82, 'name': 'refrigerator'},\n",
       " {'supercategory': 'indoor', 'id': 84, 'name': 'book'},\n",
       " {'supercategory': 'indoor', 'id': 85, 'name': 'clock'},\n",
       " {'supercategory': 'indoor', 'id': 86, 'name': 'vase'},\n",
       " {'supercategory': 'indoor', 'id': 87, 'name': 'scissors'},\n",
       " {'supercategory': 'indoor', 'id': 88, 'name': 'teddy bear'},\n",
       " {'supercategory': 'indoor', 'id': 89, 'name': 'hair drier'},\n",
       " {'supercategory': 'indoor', 'id': 90, 'name': 'toothbrush'}]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_val_coco['categories']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b5d93c48-f0af-4324-b1be-83dc057096d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'segmentation': [[304.09,\n",
       "   266.18,\n",
       "   308.95,\n",
       "   263.56,\n",
       "   313.06,\n",
       "   262.81,\n",
       "   318.3,\n",
       "   262.81,\n",
       "   322.04,\n",
       "   262.81,\n",
       "   336.25,\n",
       "   264.68,\n",
       "   338.87,\n",
       "   264.68,\n",
       "   344.85,\n",
       "   259.07,\n",
       "   353.83,\n",
       "   252.34,\n",
       "   352.7,\n",
       "   258.32,\n",
       "   344.1,\n",
       "   269.17,\n",
       "   352.33,\n",
       "   274.4,\n",
       "   357.94,\n",
       "   281.88,\n",
       "   357.94,\n",
       "   293.1,\n",
       "   356.07,\n",
       "   300.58,\n",
       "   356.44,\n",
       "   308.06,\n",
       "   354.57,\n",
       "   319.28,\n",
       "   353.45,\n",
       "   326.01,\n",
       "   351.96,\n",
       "   338.73,\n",
       "   355.32,\n",
       "   345.08,\n",
       "   354.95,\n",
       "   346.21,\n",
       "   350.09,\n",
       "   346.21,\n",
       "   341.86,\n",
       "   346.21,\n",
       "   341.11,\n",
       "   345.46,\n",
       "   343.73,\n",
       "   334.24,\n",
       "   344.85,\n",
       "   319.65,\n",
       "   344.48,\n",
       "   313.3,\n",
       "   343.73,\n",
       "   326.01,\n",
       "   341.86,\n",
       "   340.6,\n",
       "   339.62,\n",
       "   348.82,\n",
       "   341.49,\n",
       "   352.94,\n",
       "   344.1,\n",
       "   355.56,\n",
       "   343.36,\n",
       "   357.42,\n",
       "   341.11,\n",
       "   357.8,\n",
       "   338.49,\n",
       "   359.67,\n",
       "   336.25,\n",
       "   360.79,\n",
       "   334.75,\n",
       "   360.79,\n",
       "   331.01,\n",
       "   360.79,\n",
       "   328.77,\n",
       "   359.67,\n",
       "   327.27,\n",
       "   356.68,\n",
       "   329.14,\n",
       "   354.43,\n",
       "   329.14,\n",
       "   352.56,\n",
       "   328.02,\n",
       "   351.44,\n",
       "   328.77,\n",
       "   348.45,\n",
       "   328.77,\n",
       "   344.34,\n",
       "   329.14,\n",
       "   340.6,\n",
       "   329.89,\n",
       "   334.24,\n",
       "   329.52,\n",
       "   325.26,\n",
       "   328.77,\n",
       "   323.39,\n",
       "   325.03,\n",
       "   326.01,\n",
       "   322.04,\n",
       "   324.52,\n",
       "   319.05,\n",
       "   322.27,\n",
       "   320.17,\n",
       "   334.24,\n",
       "   319.8,\n",
       "   343.96,\n",
       "   319.8,\n",
       "   352.94,\n",
       "   319.42,\n",
       "   354.06,\n",
       "   311.19,\n",
       "   352.94,\n",
       "   308.2,\n",
       "   352.94,\n",
       "   304.84,\n",
       "   353.69,\n",
       "   304.09,\n",
       "   351.07,\n",
       "   306.71,\n",
       "   347.33,\n",
       "   309.7,\n",
       "   344.71,\n",
       "   309.7,\n",
       "   343.21,\n",
       "   307.45,\n",
       "   332.74,\n",
       "   307.08,\n",
       "   330.87,\n",
       "   305.21,\n",
       "   325.64,\n",
       "   305.21,\n",
       "   320.4,\n",
       "   304.09,\n",
       "   313.67,\n",
       "   303.34,\n",
       "   310.3,\n",
       "   303.34,\n",
       "   305.82,\n",
       "   302.97,\n",
       "   299.46,\n",
       "   303.34,\n",
       "   296.84,\n",
       "   301.84,\n",
       "   294.22,\n",
       "   301.1,\n",
       "   290.86,\n",
       "   301.1,\n",
       "   287.87,\n",
       "   299.6,\n",
       "   285.62,\n",
       "   297.73,\n",
       "   277.4,\n",
       "   300.72,\n",
       "   271.04,\n",
       "   304.46,\n",
       "   266.55]],\n",
       " 'area': 4290.290900000001,\n",
       " 'iscrowd': 0,\n",
       " 'image_id': 329219,\n",
       " 'bbox': [297.73, 252.34, 60.21, 108.45],\n",
       " 'category_id': 18,\n",
       " 'id': 8032}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_val_coco['annotations'][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "50485855-7e5d-4d3d-b25a-7896f3f54721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'license': 4,\n",
       " 'file_name': '000000326542.jpg',\n",
       " 'coco_url': 'http://images.cocodataset.org/val2017/000000326542.jpg',\n",
       " 'height': 480,\n",
       " 'width': 640,\n",
       " 'date_captured': '2013-11-19 17:58:52',\n",
       " 'flickr_url': 'http://farm4.staticflickr.com/3343/3451646252_bf663fdb0d_z.jpg',\n",
       " 'id': 326542}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_val_coco['images'][1220]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d60a6972-43b3-4602-898b-1893d7481d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_id_mapping = dict()\n",
    "for idx, dict_info in enumerate(data_val_coco['images']):\n",
    "    img_id_mapping[dict_info['id']] = dict_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "25728dcc-d908-4922-b156-266aa80cd819",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'segmentation': [[510.66,\n",
       "   423.01,\n",
       "   511.72,\n",
       "   420.03,\n",
       "   510.45,\n",
       "   416.0,\n",
       "   510.34,\n",
       "   413.02,\n",
       "   510.77,\n",
       "   410.26,\n",
       "   510.77,\n",
       "   407.5,\n",
       "   510.34,\n",
       "   405.16,\n",
       "   511.51,\n",
       "   402.83,\n",
       "   511.41,\n",
       "   400.49,\n",
       "   510.24,\n",
       "   398.16,\n",
       "   509.39,\n",
       "   397.31,\n",
       "   504.61,\n",
       "   399.22,\n",
       "   502.17,\n",
       "   399.64,\n",
       "   500.89,\n",
       "   401.66,\n",
       "   500.47,\n",
       "   402.08,\n",
       "   499.09,\n",
       "   401.87,\n",
       "   495.79,\n",
       "   401.98,\n",
       "   490.59,\n",
       "   401.77,\n",
       "   488.79,\n",
       "   401.77,\n",
       "   485.39,\n",
       "   398.58,\n",
       "   483.9,\n",
       "   397.31,\n",
       "   481.56,\n",
       "   396.35,\n",
       "   478.48,\n",
       "   395.93,\n",
       "   476.68,\n",
       "   396.03,\n",
       "   475.4,\n",
       "   396.77,\n",
       "   473.92,\n",
       "   398.79,\n",
       "   473.28,\n",
       "   399.96,\n",
       "   473.49,\n",
       "   401.87,\n",
       "   474.56,\n",
       "   403.47,\n",
       "   473.07,\n",
       "   405.59,\n",
       "   473.39,\n",
       "   407.71,\n",
       "   476.68,\n",
       "   409.41,\n",
       "   479.23,\n",
       "   409.73,\n",
       "   481.56,\n",
       "   410.69,\n",
       "   480.4,\n",
       "   411.85,\n",
       "   481.35,\n",
       "   414.93,\n",
       "   479.86,\n",
       "   418.65,\n",
       "   477.32,\n",
       "   420.03,\n",
       "   476.04,\n",
       "   422.58,\n",
       "   479.02,\n",
       "   422.58,\n",
       "   480.29,\n",
       "   423.01,\n",
       "   483.79,\n",
       "   419.93,\n",
       "   486.66,\n",
       "   416.21,\n",
       "   490.06,\n",
       "   415.57,\n",
       "   492.18,\n",
       "   416.85,\n",
       "   491.65,\n",
       "   420.24,\n",
       "   492.82,\n",
       "   422.9,\n",
       "   493.56,\n",
       "   424.39,\n",
       "   496.43,\n",
       "   424.6,\n",
       "   498.02,\n",
       "   423.01,\n",
       "   498.13,\n",
       "   421.31,\n",
       "   497.07,\n",
       "   420.03,\n",
       "   497.07,\n",
       "   415.15,\n",
       "   496.33,\n",
       "   414.51,\n",
       "   501.1,\n",
       "   411.96,\n",
       "   502.06,\n",
       "   411.32,\n",
       "   503.02,\n",
       "   415.04,\n",
       "   503.33,\n",
       "   418.12,\n",
       "   501.1,\n",
       "   420.24,\n",
       "   498.98,\n",
       "   421.63,\n",
       "   500.47,\n",
       "   424.39,\n",
       "   505.03,\n",
       "   423.32,\n",
       "   506.2,\n",
       "   421.31,\n",
       "   507.69,\n",
       "   419.5,\n",
       "   506.31,\n",
       "   423.32,\n",
       "   510.03,\n",
       "   423.01,\n",
       "   510.45,\n",
       "   423.01]],\n",
       " 'area': 702.1057499999998,\n",
       " 'iscrowd': 0,\n",
       " 'image_id': 289343,\n",
       " 'bbox': [473.07, 395.93, 38.65, 28.67],\n",
       " 'category_id': 18,\n",
       " 'id': 1768}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_val_coco['annotations'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d8fe8989-c6bb-4eac-9c7b-8b7eb534f5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_anno_map = defaultdict(list)\n",
    "img_anno_map = {}\n",
    "for img_data in data_val_coco['images']:\n",
    "    img_anno_map[img_data['file_name']] = []\n",
    "    \n",
    "for idx, dict_info in enumerate(data_val_coco['annotations']):\n",
    "    # print(idx)\n",
    "    img_info = img_id_mapping[dict_info['image_id']]\n",
    "    img_anno_map[img_info['file_name']].append(idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6a3831ee-e938-46e3-9fc6-19c73cb4f4e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    }
   ],
   "source": [
    "print(len(img_anno_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802df03a-6563-475f-b177-12ecd561d091",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc-autonumbering": true,
  "toc-showcode": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
